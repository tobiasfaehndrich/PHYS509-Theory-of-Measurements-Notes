\section{Lecture 13}

Thursday, October 23rd 2025

\begin{itemize}
    \item Likelihood
          \[ \mathcal{L}(\vec{x}|\theta) = \text{probability of x and not theta} \]
    \item Model $\vec{\theta}$ with and $p(\vec{x}|\vec{\theta})$
          \[ \mathcal{L} = \pi_{i=1}^{N} p(x_i|\vec{\theta}) \]
          \[ \ln \mathcal{L} = \sum_{i=1}^{N} \ln p(x_i|\vec{\theta}) \]
    \item Maximize likelihood to get best estimate of $\vec{\theta}$. Choose $\hat{\theta}$ such that:
          \[ \hat{\theta} = \text{argmax}_{\vec{\theta}} \mathcal{L}(\vec{x}|\vec{\theta}) \]
          \[ \pdv{\ln \mathcal{L(\vec{\theta})}}{\theta} \Big|_{\hat{\theta}} = 0 \]
    \item Shape of $\vec{a}$ distribution. Then $\ln \mathcal{L}(a) $ around $\hat{a}$ is approximately quadratic.
    \item True $a = \hat{a}$ expand about $a_0$:
    \item Taylor expansion:
          \[ f(a) = f(a_0) + (\hat{a} - a_0) f'(a_\star) \qquad \text{where } a_{\star} \text{ is between } \hat{a} \text{ and } a_0 \]
    \item So, for $f = \pdv{\ln \mathcal{L}(a)}{a}$:
          \[ 0 = \pdv{\ln \mathcal{L}(a)}{a} \Big|_{a_0} + (\hat{a} - a_0) \pdv[2]{\ln \mathcal{L}(a)}{a} \Big|_{a_{\star}} \]
    \item Large n for consistent $\hat{a} \to a_0$:
          \[ \lim_{n \to \infty} \pdv[2]{\ln \mathcal{L}(a)}{a} \Big|_{a_{\star}} = \lim_{n \to \infty} \sum_i \pdv[2]{\ln p(x_i|a)}{a} \Big|_{a_{\star}} \approx \lim_{n} n \int p(x|a) \pdv[2]{\ln p(x|a)}{a} \Big|_{a_{\star}} dx \]

    \item Sum over samples $x_i$ drawn from $p(x|a)$.

          \[ = \lim_{n \to \infty} n E\left( \pdv[2]{\ln p(x|a)}{a} \Big|_{a_{\star}} \right) \]
          \[ = E \left( \pdv[2]{\ln \mathcal{L}}{a} \Big|_{a_{\star}} \right) \]
          \[ \hat{a} - a_0 = - \frac{\pdv{\ln \mathcal{L}(a)}{a} \Big|_{a_0}}{E\left( \pdv[2]{\ln \mathcal{L}}{a} \Big|_{a_{\star}} \right)} \]
          \[ 0 = \pdv{\ln \mathcal{L}(a)}{a} \Big|_{a_0} + (\hat{a} - a_0) \pdv[2]{\ln \mathcal{L}(a)}{a} \Big|_{a_{\star}} \]
          \[ \int \mathcal{L}(\vec{x}|a) d\vec{x} = 1 \]
          \[ \Rightarrow \int \pdv{\mathcal{L}(\vec{x}|a)}{a} d\vec{x} = 0 \]
          \[ \pdv{\mathcal{L}}{a} = \pdv{\ln \mathcal{L}}{a} \mathcal{L} \]
          \[ \pdv{\ln \mathcal{L}}{a} = \sum_{i=1}^{n} \pdv{\ln p(x|a)}{a} \]
    \item sum of n variables with 0 mean.
    \item By CLT, for large n, $\pdv{\ln \mathcal{L}}{a}$ is Gaussian with mean 0.
          \[ \boxed{E\left(\pdv[2]{\ln \mathcal{L}}{a} \right) = - E \left( \left( \pdv[2]{\ln \mathcal{L}}{a} \right)^2 \right) }\]

    \item Variance of $\hat{a}-a_0$:
          \[ \text{Var}(\hat{a} - a_0) = \frac{\text{Var}\left( \pdv{\ln \mathcal{L}(a)}{a} \Big|_{a_0} \right)}{\left( E\left( \pdv[2]{\ln \mathcal{L}}{a} \Big|_{a_{\star}} \right) \right)^2} \]
          \[ = \frac{E\left( \left( \pdv{\ln \mathcal{L}(a)}{a} \Big|_{a_0} \right)^2 \right)}{\left( E\left( \pdv[2]{\ln \mathcal{L}}{a} \Big|_{a_{\star}} \right) \right)^2} \]
          \[ = -\frac{E\left( \pdv[2]{\ln \mathcal{L}}{a} \Big|_{a_0} \right)}{\left( E\left( \pdv[2]{\ln \mathcal{L}}{a} \Big|_{a_{\star}} \right) \right)^2} \]
    \item When $n \to \infty$, $a_{\star} \to a_0$ and $\hat{a} \to a_0$:
          \[ \boxed{\text{Var}(\hat{a}) = -\frac{1}{E\left( \pdv[2]{\ln \mathcal{L}}{a} \Big|_{a_0} \right)} } \]
    \item Fisher Information matrix:
          \[ E( \pdv[2]{\ln \mathcal{L}}{a}) \]
    \item For large n, $\hat{a} \to a_0$, Estimate E( ) by observed value.  $\pdv[2]{\ln \mathcal{L}}{a} \Big|_{\hat{a}}$
    \item So estimate of variance of $\hat{a} - a_0$ is:
          \[ \boxed{\text{Var}(\hat{a}-a_0) = -\frac{1}{\pdv[2]{\ln \mathcal{L}}{a} \Big|_{\hat{a}}} } \]

    \item Taylor expansion again:
          \[ \pdv{\ln \mathcal{L}(a)}{a} = \cancelto{0}{\pdv{\ln \mathcal{L}(a)}{a} \Big|_{\hat{a}}} + (a - \hat{a}) \pdv[2]{\ln \mathcal{L}(a)}{a} \Big|_{\hat{a}} + \ldots \]
          where $\pdv[2]{\ln \mathcal{L}(a)}{a} \Big|_{\hat{a}} = -\frac{1}{V(\hat{a})}$
          \[ \frac{-(a-\hat{a})}{V(\hat{a})} + \ldots \]
    \item Note that $V(\hat{a} - a_0) = V(\hat{a})$ because $a_0$ is constant and doesnt change the variance (it just shifts the distribution).
    \item So,
          \[ \ln \mathcal{L}(a) = \ldots \text{ missed this part} \]
    \item Note that the value you get from the maximum liklihood does not give information on how good the fit is. It is just relative to other values of the parameters.
    \item Kolmogorov-Smirnov test for goodness of fit (KS):
          \begin{enumerate}
              \item Order data points $\{t_i\}$ such that $t_0 \leq t_1 \leq t_2 \leq \ldots \leq t_N$
              \item Form an accumulator F (same model cdf C).
          \end{enumerate}
    \item Metric $\text{max}|F(t_i) - C(t_i)|$
\end{itemize}